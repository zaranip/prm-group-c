{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f88641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from typing import Tuple, Dict\n",
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb4f3550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DD      23.3362\n",
      "KDP     19.3963\n",
      "T       13.2744\n",
      "BX      12.6662\n",
      "OKE     12.3938\n",
      "         ...   \n",
      "PSA      5.0254\n",
      "ES       5.0145\n",
      "PAYX     5.0132\n",
      "EQR      4.9816\n",
      "KLAC     4.9253\n",
      "Name: 2015-07-24 00:00:00, Length: 71, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "DATA_PATH = \"data/spx_data_weekly.xlsx\"\n",
    "\n",
    "spx_df = pd.read_excel(DATA_PATH,sheet_name=\"spx data\",header=[0, 1],index_col=0)\n",
    "sector_df = pd.read_excel(DATA_PATH,sheet_name=\"sector data\",header=[0, 1],index_col=0)\n",
    "additional_df = pd.read_excel(DATA_PATH,sheet_name=\"additional data\",header=[0, 1],index_col=0)\n",
    "\n",
    "# Ensure dates sorted\n",
    "spx_df = spx_df.sort_index()\n",
    "sector_df = sector_df.sort_index()\n",
    "additional_df = additional_df.sort_index()\n",
    "\n",
    "# Convenience views\n",
    "px_spx = spx_df.xs(\"PX_LAST\", axis=1, level=1)          # stock prices\n",
    "dy_spx = spx_df.xs(\"EQY_DVD_YLD_IND\", axis=1, level=1)  # stock dividend yield\n",
    "pe_spx = spx_df.xs(\"PE_RATIO\", axis=1, level=1)         # PE Ratio\n",
    "\n",
    "px_sector = sector_df.xs(\"PX_LAST\", axis=1, level=1)    # sector prices\n",
    "px_add = additional_df.xs(\"PX_LAST\", axis=1, level=1)   # SPY, IEF, etc.\n",
    "\n",
    "# Weekly returns\n",
    "ret_spx = px_spx.pct_change()\n",
    "ret_sector = px_sector.pct_change()\n",
    "ret_add = px_add.pct_change()\n",
    "\n",
    "spy_ret = ret_add[\"SPY\"]  # market\n",
    "\n",
    "\n",
    "print(dy_spx.loc[\"2015-07-24\", :].nlargest(71))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf1df0",
   "metadata": {},
   "source": [
    "<p style=\"font-size:28px;\">1. Data Processing </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "672f81ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers with >= 5 years continuous weekly data: 485\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "MIN_WEEKS_5Y = 52 * 5\n",
    "\n",
    "\n",
    "def max_consecutive_non_nan(series: pd.Series) -> int:\n",
    "\n",
    "    mask = series.notna().to_numpy()\n",
    "    if not mask.any():\n",
    "        return 0\n",
    "\n",
    "    # Run-length encoding on boolean array\n",
    "    max_run = 0\n",
    "    current = 0\n",
    "    for v in mask:\n",
    "        if v:\n",
    "            current += 1\n",
    "            max_run = max(max_run, current)\n",
    "        else:\n",
    "            current = 0\n",
    "    return max_run\n",
    "\n",
    "\n",
    "def filter_tickers_with_5y_prices(price_df: pd.DataFrame,min_weeks: int = MIN_WEEKS_5Y) -> pd.Index:\n",
    "\n",
    "    keep = []\n",
    "    for ticker in price_df.columns:\n",
    "        series = price_df[ticker]\n",
    "        max_run = max_consecutive_non_nan(series)\n",
    "        if max_run >= min_weeks:\n",
    "            keep.append(ticker)\n",
    "    return pd.Index(keep)\n",
    "\n",
    "\n",
    "tickers_5y = filter_tickers_with_5y_prices(px_spx)\n",
    "px_spx = px_spx[tickers_5y]\n",
    "dy_spx = dy_spx[tickers_5y]\n",
    "ret_spx = ret_spx[tickers_5y]\n",
    "\n",
    "print(f\"Tickers with >= 5 years continuous weekly data: {len(tickers_5y)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897375ee",
   "metadata": {},
   "source": [
    "<p style=\"font-size:28px;\">1.1. Data Processing </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3368047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest-yielding stock in the entire panel: TRGP on 2020-04-03 00:00:00\n",
      "Dividend Yield: 64.8\n",
      "\n",
      "Lowest-yielding stock in the entire panel: COO on 2021-09-03 00:00:00\n",
      "Dividend Yield: 0.0132\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# assuming valid_dates is built from the full panel, e.g.:\n",
    "valid_dates = dy_spx.index\n",
    "\n",
    "for t in valid_dates:\n",
    "    # For each date, get the row of dividend yields and drop NaNs\n",
    "    row = dy_spx.loc[t].dropna()   # <-- use full-data panel here\n",
    "\n",
    "    # Ticker with highest and lowest yield on that date\n",
    "    top = row.idxmax()\n",
    "    bot = row.idxmin()\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"date\": t,\n",
    "            \"highest_ticker\": top,\n",
    "            \"highest_yield\": row[top],\n",
    "            \"lowest_ticker\": bot,\n",
    "            \"lowest_yield\": row[bot],\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Row with highest yield across ALL dates/tickers (panel-wide max)\n",
    "row_highest = df_results.loc[df_results[\"highest_yield\"].idxmax()]\n",
    "\n",
    "# Row with lowest yield across ALL dates/tickers (panel-wide min)\n",
    "row_lowest = df_results.loc[df_results[\"lowest_yield\"].idxmin()]\n",
    "\n",
    "print(\n",
    "    f'Highest-yielding stock in the entire panel: '\n",
    "    f'{row_highest[\"highest_ticker\"]} on {row_highest[\"date\"]}'\n",
    ")\n",
    "print(f'Dividend Yield: {row_highest[\"highest_yield\"]:.4}\\n')\n",
    "\n",
    "print(\n",
    "    f'Lowest-yielding stock in the entire panel: '\n",
    "    f'{row_lowest[\"lowest_ticker\"]} on {row_lowest[\"date\"]}'\n",
    ")\n",
    "print(f'Dividend Yield: {row_lowest[\"lowest_yield\"]:.4}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d62db7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest dividend-yielding stock (52-week average): MO\n",
      "Dividend Yield: 7.9489\n",
      "\n",
      "Lowest dividend-yielding stock (52-week average): NVDA\n",
      "Dividend Yield: 0.0318\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dy_trailing_52 = dy_spx.rolling(window=52, min_periods=52).mean()\n",
    "valid_dates = dy_trailing_52.dropna(how=\"all\").index\n",
    "\n",
    "last_date = dy_trailing_52.dropna(how=\"all\").index[-1]\n",
    "dy_last = dy_trailing_52.loc[last_date].dropna()\n",
    "\n",
    "highest = dy_last.idxmax()\n",
    "lowest = dy_last.idxmin()\n",
    "\n",
    "print(f\"Highest dividend-yielding stock (52-week average): {highest}\")\n",
    "print(f\"Dividend Yield: {dy_last[highest]:.4f}\\n\")\n",
    "\n",
    "print(f\"Lowest dividend-yielding stock (52-week average): {lowest}\")\n",
    "print(f\"Dividend Yield: {dy_last[lowest]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62801d7",
   "metadata": {},
   "source": [
    "**Was it driven more by changes in D or P?**</br>\n",
    "TRGP's extreme yield is Price driven. COO’s small-yield is dividend driven, not price-driven. It pays negligible dividends, so the yield rounds down to zero. MO's high dividend yield is fundamentally dividend driven because the dividend payout is extremely large. NVDA's extremely low dividend yield is Price driven because the dividend is tiny and basically irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94732d6d",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"font-size:28px;\">1.2. A Carry Strategy & 1.3. Long-Short </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "44629bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0005570425510055037)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def top_20pct_dy_index(row: pd.Series, top_frac: float = 0.2):\n",
    "    row = row.dropna()\n",
    "    n = len(row)\n",
    "    num =int(np.floor(top_frac * n))\n",
    "    k_top = max(1,num)\n",
    "    top_vals = row.nlargest(k_top)\n",
    "\n",
    "    return top_vals.index\n",
    "\n",
    "top_idx_per_date = dy_spx.apply(lambda row: top_20pct_dy_index(row, top_frac=0.2),axis=1)\n",
    "\n",
    "prices_top20 = {}\n",
    "\n",
    "\n",
    "for date, tickers in top_idx_per_date.items():\n",
    "    k=len(tickers)\n",
    "    prices_top20[date] = ret_spx.loc[date, tickers] \n",
    "    \n",
    "prices_top20_df = pd.DataFrame.from_dict(prices_top20, orient=\"index\")\n",
    "prices_top20_df.index.name = \"date\"\n",
    "\n",
    "row_means_top = prices_top20_df.mean(axis=1, skipna=True)\n",
    "row_means_top.mean(skipna=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5ebae87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.004234821236993323)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def bottom_20pct_dy_index(row: pd.Series, bottom_frac: float = 0.2):\n",
    "    row = row.dropna()\n",
    "    n = len(row)\n",
    "    num =int(np.floor(bottom_frac * n))\n",
    "    k_top = max(1,num)\n",
    "    bottom_vals = row.nsmallest(k_top)\n",
    "\n",
    "    return bottom_vals.index\n",
    "\n",
    "bottom_idx_per_date = dy_spx.apply(lambda row: bottom_20pct_dy_index(row, bottom_frac=0.2),axis=1)\n",
    "\n",
    "\n",
    "prices_bottom20 = {}\n",
    "\n",
    "\n",
    "for date, tickers in bottom_idx_per_date.items():\n",
    "    k=len(tickers)\n",
    "   \n",
    "    prices_bottom20[date] = ret_spx.loc[date, tickers] \n",
    "\n",
    "prices_bottom20_df = pd.DataFrame.from_dict(prices_bottom20, orient=\"index\")\n",
    "prices_bottom20_df.index.name = \"date\"\n",
    "\n",
    "row_means_bottom = prices_bottom20_df.mean(axis=1, skipna=True)\n",
    "\n",
    "ls_strat=row_means_top-row_means_bottom\n",
    "ls_strat.mean(skipna=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f294513",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"font-size:28px;\">1.4. Performance </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d570628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann_mean</th>\n",
       "      <th>ann_vol</th>\n",
       "      <th>sharpe</th>\n",
       "      <th>skew</th>\n",
       "      <th>VaR_5%</th>\n",
       "      <th>CVaR_5%</th>\n",
       "      <th>max_drawdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LO</th>\n",
       "      <td>0.028966</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.132569</td>\n",
       "      <td>-0.368940</td>\n",
       "      <td>-0.039660</td>\n",
       "      <td>-0.071357</td>\n",
       "      <td>-0.494195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LS</th>\n",
       "      <td>-0.220211</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>-1.724086</td>\n",
       "      <td>0.071274</td>\n",
       "      <td>-0.031176</td>\n",
       "      <td>-0.044842</td>\n",
       "      <td>-0.899416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPY</th>\n",
       "      <td>0.140826</td>\n",
       "      <td>0.173193</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>-0.595027</td>\n",
       "      <td>-0.033571</td>\n",
       "      <td>-0.056766</td>\n",
       "      <td>-0.318291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ann_mean   ann_vol    sharpe      skew    VaR_5%   CVaR_5%  max_drawdown\n",
       "LO   0.028966  0.218500  0.132569 -0.368940 -0.039660 -0.071357     -0.494195\n",
       "LS  -0.220211  0.127726 -1.724086  0.071274 -0.031176 -0.044842     -0.899416\n",
       "SPY  0.140826  0.173193  0.813116 -0.595027 -0.033571 -0.056766     -0.318291"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def portfolio_stats(ret: pd.Series,periods_per_year: int = 52) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute annualized mean, vol, Sharpe, skew, VaR(5%), CVaR(5%), max drawdown.\n",
    "    \"\"\"\n",
    "    ret = ret.dropna()\n",
    "\n",
    "    mu_ann = ret.mean() * periods_per_year\n",
    "    vol_ann = ret.std() * np.sqrt(periods_per_year)\n",
    "    sharpe = mu_ann / vol_ann \n",
    "\n",
    "    skew = ret.skew()\n",
    "    var_5 = ret.quantile(0.05)\n",
    "    cvar_5 = ret[ret <= var_5].mean()\n",
    "\n",
    "    value = (1 + ret).cumprod()\n",
    "    peak = value.cummax()\n",
    "    dd = (value / peak) - 1.0\n",
    "    max_dd = dd.min()\n",
    "\n",
    "    return {\n",
    "        \"ann_mean\": mu_ann,\n",
    "        \"ann_vol\": vol_ann,\n",
    "        \"sharpe\": sharpe,\n",
    "        \"skew\": skew,\n",
    "        \"VaR_5%\": var_5,\n",
    "        \"CVaR_5%\": cvar_5,\n",
    "        \"max_drawdown\": max_dd,\n",
    "    }\n",
    "\n",
    "\n",
    "lo_ret = row_means_top          # long-only top 20% portfolio\n",
    "ls_ret = ls_strat               # long–short (top – bottom)\n",
    "\n",
    "spy_ret_aligned = spy_ret.loc[lo_ret.index]  # align with LO for comparison\n",
    "\n",
    "lo_stats = portfolio_stats(lo_ret)\n",
    "ls_stats = portfolio_stats(ls_ret)\n",
    "spy_stats = portfolio_stats(spy_ret_aligned)\n",
    "\n",
    "\n",
    "stats_df = pd.DataFrame(\n",
    "    {\n",
    "        \"LO\": lo_stats,\n",
    "        \"LS\": ls_stats,\n",
    "        \"SPY\": spy_stats,\n",
    "    }\n",
    ").T  # strategies as rows\n",
    "\n",
    "stats_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f4b1a",
   "metadata": {},
   "source": [
    "<p style=\"font-size:28px;\">2. Attribution </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d0a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LO vs SPY ===\n",
      "alpha_ann: -0.00764408963822734\n",
      "beta_SPY: 0.9585387007739592\n",
      "R2: 0.6502900373100452\n",
      "=== LS vs SPY ===\n",
      "alpha_ann: -0.0217688309239376\n",
      "beta_SPY: -0.10449807030491233\n",
      "R2: 0.02307319974463462\n",
      "=== LO vs Sectors ===\n",
      "alpha_ann: 0.03067323056699773\n",
      "R2: 0.9436097966920474\n",
      "const    0.000590\n",
      "XLK     -0.128193\n",
      "XLI      0.112673\n",
      "XLF      0.292003\n",
      "XLC      0.087623\n",
      "XLRE     0.318398\n",
      "XLE      0.177915\n",
      "XLY     -0.038016\n",
      "XLB      0.110484\n",
      "XLV     -0.074579\n",
      "XLU      0.143052\n",
      "XLP      0.017924\n",
      "dtype: float64\n",
      "=== LS vs Sectors ===\n",
      "alpha_ann: 0.005551136144158756\n",
      "R2: 0.6810891153892076\n",
      "const    0.000107\n",
      "XLK     -0.305949\n",
      "XLI     -0.209150\n",
      "XLF      0.237347\n",
      "XLC      0.073642\n",
      "XLRE     0.250666\n",
      "XLE      0.177005\n",
      "XLY     -0.150000\n",
      "XLB     -0.010100\n",
      "XLV     -0.314691\n",
      "XLU      0.159482\n",
      "XLP      0.084029\n",
      "dtype: float64\n",
      "=== LO vs SPY + MAG ===\n",
      "alpha_ann: 0.07280162919942507\n",
      "const    0.001400\n",
      "SPY      1.567557\n",
      "MAG     -0.484362\n",
      "dtype: float64\n",
      "R2: 0.7768486115628447\n",
      "=== LS vs SPY + MAG ===\n",
      "alpha_ann: 0.036390311494535456\n",
      "const    0.000700\n",
      "SPY      0.335799\n",
      "MAG     -0.350175\n",
      "dtype: float64\n",
      "R2: 0.22055413543100733\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def ols_regression(\n",
    "    y: pd.Series,\n",
    "    X: pd.DataFrame,\n",
    ") -> sm.regression.linear_model.RegressionResultsWrapper:\n",
    "    \"\"\"\n",
    "    Run OLS of y on X with a constant.\n",
    "    \"\"\"\n",
    "    combined = pd.concat([y, X], axis=1).dropna()\n",
    "    y_clean = combined.iloc[:, 0]\n",
    "    X_clean = combined.iloc[:, 1:]\n",
    "    X_const = sm.add_constant(X_clean)\n",
    "    model = sm.OLS(y_clean, X_const).fit()\n",
    "    return model\n",
    "\n",
    "\n",
    "# 2.1 – Market LFD: regress LO & LS on SPY\n",
    "\n",
    "lo_ret_aligned = lo_ret.dropna()\n",
    "ls_ret_aligned = ls_ret.dropna()\n",
    "spy_for_lo = spy_ret.loc[lo_ret_aligned.index]\n",
    "spy_for_ls = spy_ret.loc[ls_ret_aligned.index]\n",
    "\n",
    "model_lo_spy = ols_regression(lo_ret_aligned, spy_for_lo.to_frame(\"SPY\"))\n",
    "model_ls_spy = ols_regression(ls_ret_aligned, spy_for_ls.to_frame(\"SPY\"))\n",
    "\n",
    "# Annualize alpha (weekly -> annual)\n",
    "def annualize_alpha(\n",
    "    model: sm.regression.linear_model.RegressionResultsWrapper,\n",
    "    periods_per_year: int = 52,\n",
    ") -> float:\n",
    "    return model.params[\"const\"] * periods_per_year\n",
    "\n",
    "\n",
    "print(\"=== LO vs SPY ===\")\n",
    "print(\"alpha_ann:\", annualize_alpha(model_lo_spy))\n",
    "print(\"beta_SPY:\", model_lo_spy.params[\"SPY\"])\n",
    "print(\"R2:\", model_lo_spy.rsquared)\n",
    "\n",
    "print(\"=== LS vs SPY ===\")\n",
    "print(\"alpha_ann:\", annualize_alpha(model_ls_spy))\n",
    "print(\"beta_SPY:\", model_ls_spy.params[\"SPY\"])\n",
    "print(\"R2:\", model_ls_spy.rsquared)\n",
    "\n",
    "# 2.2 – Sector regression (LFD wrt sectors)\n",
    "# Use sector ETF weekly returns\n",
    "sector_rets = ret_sector  # columns: sector tickers\n",
    "\n",
    "sector_for_lo = sector_rets.loc[lo_ret_aligned.index]\n",
    "sector_for_ls = sector_rets.loc[ls_ret_aligned.index]\n",
    "\n",
    "model_lo_sector = ols_regression(lo_ret_aligned, sector_for_lo)\n",
    "model_ls_sector = ols_regression(ls_ret_aligned, sector_for_ls)\n",
    "\n",
    "print(\"=== LO vs Sectors ===\")\n",
    "print(\"alpha_ann:\", annualize_alpha(model_lo_sector))\n",
    "print(\"R2:\", model_lo_sector.rsquared)\n",
    "print(model_lo_sector.params)\n",
    "\n",
    "print(\"=== LS vs Sectors ===\")\n",
    "print(\"alpha_ann:\", annualize_alpha(model_ls_sector))\n",
    "print(\"R2:\", model_ls_sector.rsquared)\n",
    "print(model_ls_sector.params)\n",
    "\n",
    "# 2.4 – MAG portfolio & two-factor regression (SPY + MAG)\n",
    "\n",
    "MAG_TICKERS = [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"NVDA\", \"META\", \"TSLA\"]\n",
    "common_mag = [t for t in MAG_TICKERS if t in ret_spx.columns]\n",
    "mag_ret = ret_spx[common_mag].mean(axis=1)\n",
    "\n",
    "mag_for_lo = mag_ret.loc[lo_ret_aligned.index]\n",
    "mag_for_ls = mag_ret.loc[ls_ret_aligned.index]\n",
    "spy_for_lo2 = spy_for_lo  # already aligned\n",
    "spy_for_ls2 = spy_for_ls\n",
    "\n",
    "X_lo_2f = pd.concat(\n",
    "    [spy_for_lo2.rename(\"SPY\"), mag_for_lo.rename(\"MAG\")],\n",
    "    axis=1,\n",
    ")\n",
    "X_ls_2f = pd.concat(\n",
    "    [spy_for_ls2.rename(\"SPY\"), mag_for_ls.rename(\"MAG\")],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "model_lo_2f = ols_regression(lo_ret_aligned, X_lo_2f)\n",
    "model_ls_2f = ols_regression(ls_ret_aligned, X_ls_2f)\n",
    "\n",
    "print(\"=== LO vs SPY + MAG ===\")\n",
    "print(\"alpha_ann:\", annualize_alpha(model_lo_2f))\n",
    "print(model_lo_2f.params)\n",
    "print(\"R2:\", model_lo_2f.rsquared)\n",
    "\n",
    "print(\"=== LS vs SPY + MAG ===\")\n",
    "print(\"alpha_ann:\", annualize_alpha(model_ls_2f))\n",
    "print(model_ls_2f.params)\n",
    "print(\"R2:\", model_ls_2f.rsquared)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed99d07",
   "metadata": {},
   "source": [
    "<p style=\"font-size:28px;\">3. Dynamic hedged </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a57231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LO sector-hedged stats: {'ann_mean': np.float64(-0.020428350500080954), 'ann_vol': np.float64(0.05678025222066874), 'sharpe': np.float64(-0.35977914329596394), 'skew': np.float64(-0.07006092645003176), 'VaR_5%': np.float64(-0.01283681204353844), 'CVaR_5%': np.float64(-0.01671585836954045), 'max_drawdown': -0.08362163947434009}\n",
      "LS sector-hedged stats: {'ann_mean': np.float64(-0.06710267962971729), 'ann_vol': np.float64(0.07622898018628653), 'sharpe': np.float64(-0.8802778085937053), 'skew': np.float64(0.06426242778012929), 'VaR_5%': np.float64(-0.018282011803087462), 'CVaR_5%': np.float64(-0.021617215817993852), 'max_drawdown': -0.14589358086068227}\n",
      "LO hedged vs sectors R2: 0.3560757684325381\n",
      "LS hedged vs sectors R2: 0.3487394737600158\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ROLL_WIN = 52 * 5  # 5 years\n",
    "\n",
    "\n",
    "def rolling_sector_betas(\n",
    "    strat_ret: pd.Series,\n",
    "    sector_ret: pd.DataFrame,\n",
    "    window: int = ROLL_WIN,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each date t (after initial window),\n",
    "    estimate betas from regression of strat_ret on sector_ret over past 'window' weeks.\n",
    "    Returns a DataFrame of betas indexed by t (same as strat_ret index, truncated).\n",
    "    \"\"\"\n",
    "    # align series and sector returns\n",
    "    combined = pd.concat(\n",
    "        [strat_ret.rename(\"strat\"), sector_ret],\n",
    "        axis=1,\n",
    "    ).dropna()\n",
    "    dates = combined.index\n",
    "    cols_sector = sector_ret.columns\n",
    "\n",
    "    betas = []\n",
    "\n",
    "    for i in range(window, len(dates)):\n",
    "        window_dates = dates[i - window : i]\n",
    "        sub = combined.loc[window_dates]\n",
    "        y = sub[\"strat\"]\n",
    "        X = sub[cols_sector]\n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_const).fit()\n",
    "        # store betas (exclude const)\n",
    "        beta_t = model.params.drop(\"const\")\n",
    "        beta_t.name = dates[i]\n",
    "        betas.append(beta_t)\n",
    "\n",
    "    if not betas:\n",
    "        return pd.DataFrame(columns=cols_sector)\n",
    "\n",
    "    beta_df = pd.DataFrame(betas)\n",
    "    beta_df = beta_df.reindex(columns=cols_sector)\n",
    "    return beta_df\n",
    "\n",
    "\n",
    "def sector_hedged_returns(\n",
    "    strat_ret: pd.Series,\n",
    "    sector_ret: pd.DataFrame,\n",
    "    betas: pd.DataFrame,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Given strategy returns, sector returns, and rolling betas,\n",
    "    compute hedged returns = strat_ret - sum_j beta_j(t-1)*sector_ret_j(t).\n",
    "    We align on dates where betas are available.\n",
    "    \"\"\"\n",
    "    common_dates = betas.index.intersection(sector_ret.index).intersection(\n",
    "        strat_ret.index\n",
    "    )\n",
    "    common_dates = common_dates.sort_values()\n",
    "\n",
    "    hedged = []\n",
    "\n",
    "    for t in common_dates[1:]:\n",
    "        # use beta from previous date as hedge ratio\n",
    "        t_prev = common_dates[common_dates.get_loc(t) - 1]\n",
    "        b = betas.loc[t_prev]  # betas at t_prev\n",
    "        sector_t = sector_ret.loc[t, b.index]\n",
    "        hedge = (b * sector_t).sum()\n",
    "        hedged.append((t, strat_ret.loc[t] - hedge))\n",
    "\n",
    "    return pd.Series(dict(hedged)).sort_index()\n",
    "\n",
    "\n",
    "# Compute rolling betas and hedged returns for LO and LS strategies\n",
    "lo_sector_ret = sector_rets.loc[lo_ret.index]\n",
    "ls_sector_ret = sector_rets.loc[ls_ret.index]\n",
    "\n",
    "lo_betas = rolling_sector_betas(lo_ret, lo_sector_ret)\n",
    "ls_betas = rolling_sector_betas(ls_ret, ls_sector_ret)\n",
    "\n",
    "lo_hedged = sector_hedged_returns(lo_ret, lo_sector_ret, lo_betas)\n",
    "ls_hedged = sector_hedged_returns(ls_ret, ls_sector_ret, ls_betas)\n",
    "\n",
    "lo_hedged_stats = portfolio_stats(lo_hedged)\n",
    "ls_hedged_stats = portfolio_stats(ls_hedged)\n",
    "\n",
    "print(\"LO sector-hedged stats:\", lo_hedged_stats)\n",
    "print(\"LS sector-hedged stats:\", ls_hedged_stats)\n",
    "\n",
    "# Sector LFD of hedged strategies (should have much lower R^2)\n",
    "lo_hedged_model = ols_regression(\n",
    "    lo_hedged,\n",
    "    sector_rets.loc[lo_hedged.index],\n",
    ")\n",
    "ls_hedged_model = ols_regression(\n",
    "    ls_hedged,\n",
    "    sector_rets.loc[ls_hedged.index],\n",
    ")\n",
    "\n",
    "print(\"LO hedged vs sectors R2:\", lo_hedged_model.rsquared)\n",
    "print(\"LS hedged vs sectors R2:\", ls_hedged_model.rsquared)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aa38ef",
   "metadata": {},
   "source": [
    "<p style=\"font-size:28px;\">4. Assessing the Forecast </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca54edf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast vs raw returns corr: -0.008731231153207246\n",
      "Forecast vs raw returns R2: -0.004712222544838829\n",
      "Forecast vs SPY-hedged residuals corr: -0.00814064412373235\n",
      "Forecast vs SPY-hedged residuals R2: 6.570341231737498e-05\n",
      "Forecast vs sector-hedged residuals corr: -0.006056369966100719\n",
      "Forecast vs sector-hedged residuals R2: -0.0002183342115611442\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 4.1 – Forecast vs raw returns\n",
    "\n",
    "def build_forecasts(\n",
    "    dy_trailing: pd.DataFrame,\n",
    "    top_frac: float = 0.2,\n",
    "    bottom_frac: float = 0.2,\n",
    "    pos_forecast: float = 0.001,\n",
    "    neg_forecast: float = -0.001,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each date t, mark:\n",
    "      +pos_forecast for top_frac names,\n",
    "      neg_forecast for bottom_frac names,\n",
    "      0 otherwise.\n",
    "    \"\"\"\n",
    "    forecasts = pd.DataFrame(\n",
    "        0.0, index=dy_trailing.index, columns=dy_trailing.columns\n",
    "    )\n",
    "\n",
    "    for t in dy_trailing.index:\n",
    "        dy_t = dy_trailing.loc[t]\n",
    "        dy_t = dy_t.dropna()\n",
    "        if dy_t.empty:\n",
    "            continue\n",
    "\n",
    "        n = len(dy_t)\n",
    "        k_top = max(1, int(np.floor(top_frac * n)))\n",
    "        k_bot = max(1, int(np.floor(bottom_frac * n)))\n",
    "\n",
    "        top = dy_t.nlargest(k_top).index\n",
    "        bottom = dy_t.nsmallest(k_bot).index\n",
    "\n",
    "        forecasts.loc[t, top] = pos_forecast\n",
    "        forecasts.loc[t, bottom] = neg_forecast\n",
    "\n",
    "    return forecasts\n",
    "\n",
    "\n",
    "forecasts = build_forecasts(dy_trailing_52)\n",
    "\n",
    "# Align forecasts at t with returns at t+1\n",
    "common_dates = forecasts.index.intersection(ret_spx.index)\n",
    "common_dates = common_dates.sort_values()\n",
    "\n",
    "f_list = []\n",
    "r_list = []\n",
    "\n",
    "for i in range(len(common_dates) - 1):\n",
    "    t = common_dates[i]\n",
    "    t_next = common_dates[i + 1]\n",
    "    f_t = forecasts.loc[t]\n",
    "    r_tp1 = ret_spx.loc[t_next]\n",
    "\n",
    "    # keep tickers with non-zero forecast and non-NaN return\n",
    "    mask = (f_t != 0.0) & r_tp1.notna()\n",
    "    if not mask.any():\n",
    "        continue\n",
    "\n",
    "    f_list.append(f_t[mask].to_numpy())\n",
    "    r_list.append(r_tp1[mask].to_numpy())\n",
    "\n",
    "if f_list:\n",
    "    f_all = np.concatenate(f_list)\n",
    "    r_all = np.concatenate(r_list)\n",
    "\n",
    "    corr_fr = np.corrcoef(f_all, r_all)[0, 1]\n",
    "    # R^2 from simple regression r = beta f (no intercept)\n",
    "    beta = np.dot(f_all, r_all) / np.dot(f_all, f_all)\n",
    "    r_hat = beta * f_all\n",
    "    ss_res = np.sum((r_all - r_hat) ** 2)\n",
    "    ss_tot = np.sum((r_all - r_all.mean()) ** 2)\n",
    "    r2_forecast = 1 - ss_res / ss_tot\n",
    "\n",
    "    print(\"Forecast vs raw returns corr:\", corr_fr)\n",
    "    print(\"Forecast vs raw returns R2:\", r2_forecast)\n",
    "else:\n",
    "    print(\"No f_list – check data alignment for forecasts vs raw returns.\")\n",
    "\n",
    "\n",
    "# 4.2 – Forecast vs SPY-hedged residuals\n",
    "\n",
    "def stock_betas_vs_spy(\n",
    "    ret_stock: pd.DataFrame,\n",
    "    spy_ret: pd.Series,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Estimate a single beta for each stock vs SPY over entire sample (simple).\n",
    "    \"\"\"\n",
    "    betas = {}\n",
    "    for ticker in ret_stock.columns:\n",
    "        combined = pd.concat(\n",
    "            [ret_stock[ticker].rename(\"r\"), spy_ret.rename(\"spy\")],\n",
    "            axis=1,\n",
    "        ).dropna()\n",
    "        if len(combined) < 50:\n",
    "            continue\n",
    "        X = sm.add_constant(combined[\"spy\"])\n",
    "        model = sm.OLS(combined[\"r\"], X).fit()\n",
    "        betas[ticker] = model.params[\"spy\"]\n",
    "    return pd.Series(betas)\n",
    "\n",
    "\n",
    "betas_spy = stock_betas_vs_spy(ret_spx, spy_ret)\n",
    "betas_spy = betas_spy.reindex(ret_spx.columns).fillna(0.0)\n",
    "\n",
    "# Compute residuals epsilon_{i,t} = r_{i,t} - beta_i * spy_t\n",
    "eps_spx = ret_spx.sub(spy_ret, axis=0).mul(betas_spy, axis=1)  # wrong: need broadcasting carefully\n",
    "\n",
    "# Correct residual: r_i,t - beta_i * spy_t\n",
    "# We'll recompute properly:\n",
    "eps_spx = ret_spx.copy()\n",
    "for ticker in eps_spx.columns:\n",
    "    eps_spx[ticker] = ret_spx[ticker] - betas_spy[ticker] * spy_ret\n",
    "\n",
    "# Now align forecasts at t with eps at t+1\n",
    "fe_list = []\n",
    "e_list = []\n",
    "\n",
    "for i in range(len(common_dates) - 1):\n",
    "    t = common_dates[i]\n",
    "    t_next = common_dates[i + 1]\n",
    "\n",
    "    f_t = forecasts.loc[t]\n",
    "    e_tp1 = eps_spx.loc[t_next]\n",
    "\n",
    "    mask = (f_t != 0.0) & e_tp1.notna()\n",
    "    if not mask.any():\n",
    "        continue\n",
    "\n",
    "    fe_list.append(f_t[mask].to_numpy())\n",
    "    e_list.append(e_tp1[mask].to_numpy())\n",
    "\n",
    "if fe_list:\n",
    "    f_all = np.concatenate(fe_list)\n",
    "    e_all = np.concatenate(e_list)\n",
    "\n",
    "    corr_fe = np.corrcoef(f_all, e_all)[0, 1]\n",
    "    beta_fe = np.dot(f_all, e_all) / np.dot(f_all, f_all)\n",
    "    e_hat = beta_fe * f_all\n",
    "    ss_res = np.sum((e_all - e_hat) ** 2)\n",
    "    ss_tot = np.sum((e_all - e_all.mean()) ** 2)\n",
    "    r2_fe = 1 - ss_res / ss_tot\n",
    "\n",
    "    print(\"Forecast vs SPY-hedged residuals corr:\", corr_fe)\n",
    "    print(\"Forecast vs SPY-hedged residuals R2:\", r2_fe)\n",
    "else:\n",
    "    print(\"No fe_list – check data alignment for forecasts vs residuals.\")\n",
    "\n",
    "\n",
    "# 4.3 – Forecast vs sector-hedged residuals\n",
    "\n",
    "def stock_betas_vs_sectors(\n",
    "    ret_stock: pd.DataFrame,\n",
    "    ret_sector: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Estimate one beta vector per stock vs all sectors, using full sample.\n",
    "    Returns DataFrame: index=tickers, columns=sector ETFs.\n",
    "    \"\"\"\n",
    "    betas_dict = {}\n",
    "    for ticker in ret_stock.columns:\n",
    "        combined = pd.concat(\n",
    "            [ret_stock[ticker].rename(\"r\"), ret_sector],\n",
    "            axis=1,\n",
    "        ).dropna()\n",
    "        if len(combined) < 50:\n",
    "            continue\n",
    "        y = combined[\"r\"]\n",
    "        X = combined[ret_sector.columns]\n",
    "        X_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_const).fit()\n",
    "        betas_t = model.params.drop(\"const\")\n",
    "        betas_dict[ticker] = betas_t\n",
    "    beta_df = pd.DataFrame(betas_dict).T\n",
    "    return beta_df\n",
    "\n",
    "\n",
    "beta_sectors = stock_betas_vs_sectors(ret_spx, ret_sector)\n",
    "beta_sectors = beta_sectors.reindex(index=ret_spx.columns, columns=ret_sector.columns).fillna(0.0)\n",
    "\n",
    "# Residuals u_{i,t} = r_{i,t} - sum_j beta_{ij} * sector_j,t\n",
    "u_spx = pd.DataFrame(index=ret_spx.index, columns=ret_spx.columns, dtype=float)\n",
    "\n",
    "for ticker in ret_spx.columns:\n",
    "    r_i = ret_spx[ticker]\n",
    "    b_i = beta_sectors.loc[ticker]\n",
    "    # hedged component\n",
    "    hedged_i = (ret_sector * b_i).sum(axis=1)\n",
    "    u_spx[ticker] = r_i - hedged_i\n",
    "\n",
    "fs_list = []\n",
    "u_list = []\n",
    "\n",
    "for i in range(len(common_dates) - 1):\n",
    "    t = common_dates[i]\n",
    "    t_next = common_dates[i + 1]\n",
    "\n",
    "    f_t = forecasts.loc[t]\n",
    "    u_tp1 = u_spx.loc[t_next]\n",
    "\n",
    "    mask = (f_t != 0.0) & u_tp1.notna()\n",
    "    if not mask.any():\n",
    "        continue\n",
    "\n",
    "    fs_list.append(f_t[mask].to_numpy())\n",
    "    u_list.append(u_tp1[mask].to_numpy())\n",
    "\n",
    "if fs_list:\n",
    "    f_all = np.concatenate(fs_list)\n",
    "    u_all = np.concatenate(u_list)\n",
    "\n",
    "    corr_fu = np.corrcoef(f_all, u_all)[0, 1]\n",
    "    beta_fu = np.dot(f_all, u_all) / np.dot(f_all, f_all)\n",
    "    u_hat = beta_fu * f_all\n",
    "    ss_res = np.sum((u_all - u_hat) ** 2)\n",
    "    ss_tot = np.sum((u_all - u_all.mean()) ** 2)\n",
    "    r2_fu = 1 - ss_res / ss_tot\n",
    "\n",
    "    print(\"Forecast vs sector-hedged residuals corr:\", corr_fu)\n",
    "    print(\"Forecast vs sector-hedged residuals R2:\", r2_fu)\n",
    "else:\n",
    "    print(\"No fs_list – check data alignment for forecasts vs sector residuals.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac7d7b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO sample shape: (260, 484)\n",
      "Optimal alpha: 6.660302154539462e-05\n",
      "Number of non-zero exposures: 59\n",
      "R^2 of replication: 0.7321461946817996\n",
      "Tracking error (weekly std of residuals): 0.020140311988592972\n",
      "Forecast correlation (target vs replication): 0.7545083753136952\n",
      "Mean forecast difference (weekly, target - rep): -0.0005700514056049021\n",
      "Std of forecast difference (weekly): 0.00041049110072449143\n",
      "Mean forecast difference annualized (percentage points): -2.964267309145491\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. Choose a target asset\n",
    "TARGET = \"AAPL\"\n",
    "\n",
    "# 2. Build regression dataset for LASSO:\n",
    "#    y_t = r_target,t ; X_t = returns of all OTHER stocks at t\n",
    "ret_all = ret_spx.dropna(how=\"all\")\n",
    "y = ret_all[TARGET]\n",
    "X = ret_all.drop(columns=[TARGET])\n",
    "\n",
    "combined = pd.concat([y.rename(\"y\"), X], axis=1).dropna()\n",
    "y_clean = combined[\"y\"].values\n",
    "X_clean = combined.drop(columns=[\"y\"]).values\n",
    "\n",
    "print(\"LASSO sample shape:\", X_clean.shape)  # (T, N-1)\n",
    "\n",
    "# 3. Fit LASSO with CV (sparse replication portfolio)\n",
    "lasso_cv = LassoCV(cv=5, random_state=0, max_iter=10000)\n",
    "lasso_cv.fit(X_clean, y_clean)\n",
    "\n",
    "alpha_opt = lasso_cv.alpha_\n",
    "coef = pd.Series(lasso_cv.coef_, index=X.columns)\n",
    "nonzero_weights = coef[coef != 0.0]\n",
    "\n",
    "print(\"Optimal alpha:\", alpha_opt)\n",
    "print(\"Number of non-zero exposures:\", len(nonzero_weights))\n",
    "\n",
    "# In-sample fit quality\n",
    "r2 = lasso_cv.score(X_clean, y_clean)\n",
    "y_hat = lasso_cv.predict(X_clean)\n",
    "residuals = y_clean - y_hat\n",
    "print(\"R^2 of replication:\", r2)\n",
    "print(\"Tracking error (weekly std of residuals):\", residuals.std())\n",
    "\n",
    "# 4. Build forecast series for target vs replication portfolio\n",
    "\n",
    "# Dates where we have trailing yield (for forecast) and returns\n",
    "idx_common = dy_trailing_52.index.intersection(ret_all.index)\n",
    "# Require AAPL to have a non-null trailing yield\n",
    "mask_dates = idx_common[dy_trailing_52.loc[idx_common, TARGET].notna()]\n",
    "\n",
    "# Target forecasts f_target(t) = forecast for AAPL at t\n",
    "f_target = forecasts.loc[mask_dates, TARGET]\n",
    "\n",
    "# Replication portfolio uses only non-zero LASSO weights\n",
    "rep_tickers = nonzero_weights.index\n",
    "w = nonzero_weights\n",
    "\n",
    "# f_rep(t) = sum_j w_j * f_j(t)\n",
    "f_rep = (forecasts.loc[mask_dates, rep_tickers] * w).sum(axis=1)\n",
    "\n",
    "# 5. Compare the two forecast series\n",
    "corr_forecast = np.corrcoef(f_target, f_rep)[0, 1]\n",
    "diff = f_target - f_rep\n",
    "\n",
    "print(\"Forecast correlation (target vs replication):\", corr_forecast)\n",
    "print(\"Mean forecast difference (weekly, target - rep):\", diff.mean())\n",
    "print(\"Std of forecast difference (weekly):\", diff.std())\n",
    "\n",
    "# Convert mean difference to annual % (since 0.001 ≈ 0.1% per week)\n",
    "mean_diff_annual_pct = diff.mean() * 52 * 100\n",
    "print(\"Mean forecast difference annualized (percentage points):\",\n",
    "      mean_diff_annual_pct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a963ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
