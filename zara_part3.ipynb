{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "becb5f47",
   "metadata": {},
   "source": [
    "Q3.1\n",
    "**1. Lagged regression.** Consider the regression with predictors lagged one period:\n",
    "$r_{t}^{SPY}=\\alpha^{SPY,X}+(\\beta^{SPY,X})^{\\prime}X_{t-1}+\\epsilon_{t}^{SPY,X}$ (1)\n",
    "\n",
    "Estimate (1) and report the $R^{2}$ as well as the OLS estimates for $\\alpha$ and $\\beta$. Do this for:\n",
    "* X as a single regressor, the dividend-price ratio (DP)\n",
    "* X as a single regressor, the earnings-price ratio (EP)\n",
    "* X with three regressors: DP, EP, and the 10-year yield\n",
    "\n",
    "For each, report the $R^{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "if 'part3_ready' not in globals():\n",
    "    file_path = Path('data/gmo_analysis_data.xlsx')\n",
    "    total_returns = pd.read_excel(file_path, sheet_name='total returns', parse_dates=['date']).sort_values('date')\n",
    "    signals = pd.read_excel(file_path, sheet_name='signals', parse_dates=['date'])\n",
    "    risk_free = pd.read_excel(file_path, sheet_name='risk-free rate', parse_dates=['date'])\n",
    "    risk_free = risk_free.rename(columns={'TBill 3M': 'rf_annual'})\n",
    "    risk_free['rf_monthly'] = risk_free['rf_annual'] / 12.0\n",
    "    part3_data = total_returns.merge(signals, on='date').merge(risk_free[['date', 'rf_monthly']], on='date', how='left')\n",
    "    part3_data['SPY_excess'] = part3_data['SPY'] - part3_data['rf_monthly']\n",
    "    part3_data['GMWAX_excess'] = part3_data['GMWAX'] - part3_data['rf_monthly']\n",
    "    part3_data['return_next'] = part3_data['SPY'].shift(-1)\n",
    "    part3_data['rf_next'] = part3_data['rf_monthly'].shift(-1)\n",
    "    part3_data['GMWAX_next'] = part3_data['GMWAX'].shift(-1)\n",
    "    part3_data['SPY_excess_next'] = part3_data['return_next'] - part3_data['rf_next']\n",
    "    part3_data['date_next'] = part3_data['date'].shift(-1)\n",
    "    part3_model_df = part3_data.dropna(subset=['return_next']).copy()\n",
    "    part3_model_df = part3_model_df.set_index('date_next')\n",
    "    pd.options.display.float_format = lambda value: f'{value:0.4f}'\n",
    "    part3_ready = True\n",
    "\n",
    "feature_map = {\n",
    "    'DP': ['SPX D/P'],\n",
    "    'EP': ['SPX E/P'],\n",
    "    'DP_EP': ['SPX D/P', 'SPX E/P'],\n",
    "    'DP_EP_T10': ['SPX D/P', 'SPX E/P', 'T-Note 10YR']\n",
    "}\n",
    "\n",
    "friendly = {\n",
    "    'SPX D/P': 'Beta_DP',\n",
    "    'SPX E/P': 'Beta_EP',\n",
    "    'T-Note 10YR': 'Beta_T10'\n",
    "}\n",
    "\n",
    "def ensure_2d(values):\n",
    "    array = np.asarray(values)\n",
    "    if array.ndim == 1:\n",
    "        array = array.reshape(-1, 1)\n",
    "    return array\n",
    "\n",
    "def run_ols(y, X):\n",
    "    X_array = ensure_2d(X)\n",
    "    y_array = np.asarray(y)\n",
    "    valid_mask = np.isfinite(y_array) & np.all(np.isfinite(X_array), axis=1)\n",
    "    X_valid = X_array[valid_mask]\n",
    "    y_valid = y_array[valid_mask]\n",
    "    design = np.column_stack([np.ones(len(X_valid)), X_valid])\n",
    "    coeffs, _, _, _ = np.linalg.lstsq(design, y_valid, rcond=None)\n",
    "    fitted = design @ coeffs\n",
    "    resid = y_valid - fitted\n",
    "    ss_res = np.sum(resid ** 2)\n",
    "    ss_tot = np.sum((y_valid - y_valid.mean()) ** 2)\n",
    "    r_squared = 1 - ss_res / ss_tot if ss_tot != 0 else float('nan')\n",
    "    resid_std = np.std(resid, ddof=1)\n",
    "    return coeffs, r_squared, resid_std\n",
    "\n",
    "def max_drawdown(series):\n",
    "    cumulative = (1 + series).cumprod()\n",
    "    running_peak = cumulative.cummax()\n",
    "    drawdown = cumulative / running_peak - 1\n",
    "    return drawdown.min()\n",
    "\n",
    "def annualized_moments(series):\n",
    "    mean_month = series.mean()\n",
    "    vol_month = series.std(ddof=1)\n",
    "    return mean_month * 12, vol_month * np.sqrt(12)\n",
    "\n",
    "part3_coeffs = {}\n",
    "part3_forecasts = {}\n",
    "coeff_rows = []\n",
    "\n",
    "for name, cols in feature_map.items():\n",
    "    coeffs, r_sq, resid_std = run_ols(part3_model_df['return_next'], part3_model_df[cols])\n",
    "    coeff_info = {'Model': name, 'Alpha': coeffs[0], 'R2': r_sq}\n",
    "    for col_label, beta_value in zip(cols, coeffs[1:]):\n",
    "        coeff_info[friendly[col_label]] = beta_value\n",
    "    coeff_rows.append(coeff_info)\n",
    "    part3_coeffs[name] = {'alpha': coeffs[0], 'betas': dict(zip(cols, coeffs[1:])), 'resid_std': resid_std}\n",
    "    forecast_values = np.dot(ensure_2d(part3_model_df[cols]), coeffs[1:])\n",
    "    part3_forecasts[name] = pd.Series(part3_coeffs[name]['alpha'] + forecast_values, index=part3_model_df.index)\n",
    "\n",
    "coeff_df = pd.DataFrame(coeff_rows).fillna('')\n",
    "print(coeff_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c8b637",
   "metadata": {},
   "source": [
    "All valuation regressions produce very small R squared values (below one percent) and coefficients imply that DP has the strongest weight while EP and the ten year yield contribute far less. The limited explanatory power confirms that forecasting SPY with these monthly variables remains difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac26d3",
   "metadata": {},
   "source": [
    "Q3.2\n",
    "**2. Trading strategy from forecasts.** For each of the three regressions:\n",
    "Build the forecasted SPY return: $\\hat{r}_{t+1}^{SPY}$ (forecast made using $X_{t}$ to predict $r_{t+1}^{SPY}$).\n",
    "* Set the scale (portfolio weight) to $w_{t}=100\\hat{r}_{t+1}^{SPY}$\n",
    "* Strategy return: $r_{t+1}^{x}=w_{t}r_{t+1}^{SPY}.$\n",
    "\n",
    "For each strategy, compute:\n",
    "* mean, volatility, Sharpe\n",
    "* max drawdown\n",
    "* market alpha\n",
    "* market beta\n",
    "* market information ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67255256",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_totals = {}\n",
    "strategy_excess = {}\n",
    "strategy_summary = []\n",
    "\n",
    "for name, forecast_series in part3_forecasts.items():\n",
    "    total = (forecast_series * 100) * part3_model_df['return_next']\n",
    "    total = total.dropna()\n",
    "    strategy_totals[name] = total\n",
    "    rf = part3_model_df['rf_next'].loc[total.index]\n",
    "    excess = total - rf\n",
    "    strategy_excess[name] = excess\n",
    "    mean_ann, vol_ann = annualized_moments(total)\n",
    "    excess_mean = excess.mean()\n",
    "    excess_vol = excess.std(ddof=1)\n",
    "    sharpe = (excess_mean * 12) / (excess_vol * np.sqrt(12)) if excess_vol != 0 else float('nan')\n",
    "    mdd = max_drawdown(total)\n",
    "    alpha_month, beta_value, resid_std = run_ols(excess, part3_model_df['SPY_excess_next'].loc[total.index])\n",
    "    alpha_ann = alpha_month * 12\n",
    "    info_ratio = alpha_ann / (resid_std * np.sqrt(12)) if resid_std != 0 else float('nan')\n",
    "    strategy_summary.append({\n",
    "        'Strategy': name,\n",
    "        'Mean': mean_ann,\n",
    "        'Volatility': vol_ann,\n",
    "        'Sharpe': sharpe,\n",
    "        'Max_Drawdown': mdd,\n",
    "        'Alpha': alpha_ann,\n",
    "        'Beta': beta_value,\n",
    "        'Info_Ratio': info_ratio\n",
    "    })\n",
    "\n",
    "strategy_metrics = pd.DataFrame(strategy_summary).round(4)\n",
    "strategy_metric_map = {row['Strategy']: row for row in strategy_summary}\n",
    "print(strategy_metrics.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb82f6d",
   "metadata": {},
   "source": [
    "All three base strategies deliver double digit annualized volatility with Sharpe ratios only around zero point five, and max drawdowns run between minus zero point sixty and minus zero point seventy. Alpha estimates are modest and information ratios stay below zero point fifteen, so the levered timing trades do not add much beyond market beta exposure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b683b4c3",
   "metadata": {},
   "source": [
    "Q3.3\n",
    "**3. Risk characteristics.**\n",
    "* For both strategies, the market, and GMO, compute monthly VaR at $\\pi=0.05$ (use the historical quantile).\n",
    "* The case mentions stocks under-performed short-term bonds from 2000-2011. Does the dynamic portfolio above under-perform the risk-free rate over this time?\n",
    "* Based on the regression estimates, in how many periods do we estimate a negative risk premium?\n",
    "* Do you believe the dynamic strategy takes on extra risk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd733678",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_rows = [\n",
    "    {'Series': 'SPY', 'VaR_0.05': part3_model_df['return_next'].quantile(0.05)},\n",
    "    {'Series': 'GMWAX', 'VaR_0.05': part3_model_df['GMWAX_next'].quantile(0.05)}\n",
    "]\n",
    "for name, series in strategy_totals.items():\n",
    "    var_rows.append({'Series': f'{name} strategy', 'VaR_0.05': series.quantile(0.05)})\n",
    "var_df = pd.DataFrame(var_rows).round(4)\n",
    "print('VaR table')\n",
    "print(var_df.to_string(index=False))\n",
    "\n",
    "start_period = '2000-01-31'\n",
    "end_period = '2011-12-31'\n",
    "market_excess = (part3_model_df['return_next'].loc[start_period:end_period] - part3_model_df['rf_next'].loc[start_period:end_period]).mean()\n",
    "print(f'Market mean excess two thousand to two thousand eleven: {market_excess:0.4f}')\n",
    "for name, series in strategy_totals.items():\n",
    "    excess_mean = (series.loc[start_period:end_period] - part3_model_df['rf_next'].loc[start_period:end_period]).mean()\n",
    "    print(f'{name} strategy mean excess two thousand to two thousand eleven: {excess_mean:0.4f}')\n",
    "\n",
    "negative_counts = {}\n",
    "for name, forecast in part3_forecasts.items():\n",
    "    forecast_excess = forecast - part3_model_df['rf_next']\n",
    "    negative_counts[name] = int(forecast_excess.lt(0).sum())\n",
    "print('Negative forecast counts')\n",
    "print(negative_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75edee40",
   "metadata": {},
   "source": [
    "Monthly VaR for the levered strategies sits near minus zero point zero six, in line with SPY and notably worse than GMWAX. During two thousand to two thousand eleven the dynamic portfolios still beat the risk-free rate on average (roughly twenty to twenty five basis points per month), whereas the market lagged. Forecasted risk premia are negative in only a few dozen months (mostly in the DP and DP_EP variants), so the models rarely advise under-weighting equities. Drawdowns approach minus zero point seven, so these timing schemes clearly assume far more risk than the underlying GMO funds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b96f94",
   "metadata": {},
   "source": [
    "Q4.1\n",
    "**1. Report the out-of-sample $R^{2}$**\n",
    "$R_{OOS}^{2}\\equiv1-\\frac{\\sum_{i=61}^{T}(e_{i}^{forecast})^{2}}{\\sum_{i=61}^{T}(e_{i}^{null})^{2}}$\n",
    "Did this forecasting strategy produce a positive $R_{OOS}^{2}?$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d823bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_start = 60\n",
    "X_oos = part3_model_df[['SPX D/P', 'SPX E/P']].to_numpy()\n",
    "y_oos = part3_model_df['return_next'].to_numpy()\n",
    "forecast_values = np.full(len(part3_model_df), np.nan)\n",
    "null_values = np.full(len(part3_model_df), np.nan)\n",
    "\n",
    "for idx in range(oos_start, len(part3_model_df)):\n",
    "    X_window = X_oos[:idx]\n",
    "    y_window = y_oos[:idx]\n",
    "    design = np.column_stack([np.ones(len(X_window)), X_window])\n",
    "    coeffs, _, _, _ = np.linalg.lstsq(design, y_window, rcond=None)\n",
    "    forecast_values[idx] = coeffs[0] + np.dot(X_oos[idx], coeffs[1:])\n",
    "    null_values[idx] = y_window.mean()\n",
    "\n",
    "oos_forecast = pd.Series(forecast_values, index=part3_model_df.index)\n",
    "oos_null = pd.Series(null_values, index=part3_model_df.index)\n",
    "error_forecast = part3_model_df['return_next'] - oos_forecast\n",
    "error_null = part3_model_df['return_next'] - oos_null\n",
    "rss_forecast = np.nansum(error_forecast.iloc[oos_start:] ** 2)\n",
    "rss_null = np.nansum(error_null.iloc[oos_start:] ** 2)\n",
    "r2_oos = 1 - rss_forecast / rss_null\n",
    "print(f'Out-of-sample R2: {r2_oos:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f250f6",
   "metadata": {},
   "source": [
    "$R_{OOS}^{2}$ is negative, so the DP plus EP forecaster fails to beat the expanding-mean benchmark once we restrict ourselves to information that was available in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a544096b",
   "metadata": {},
   "source": [
    "Q4.2\n",
    "**2. Redo 3.2 with OOS forecasts.** How does the OOS strategy compare to the in-sample version of 3.2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e91aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_total = (oos_forecast * 100) * part3_model_df['return_next']\n",
    "oos_total = oos_total.dropna()\n",
    "oos_total_series = oos_total\n",
    "rf_oos = part3_model_df['rf_next'].loc[oos_total.index]\n",
    "oos_excess_series = oos_total - rf_oos\n",
    "mean_ann, vol_ann = annualized_moments(oos_total)\n",
    "oos_excess_mean = oos_excess_series.mean()\n",
    "oos_excess_vol = oos_excess_series.std(ddof=1)\n",
    "oos_sharpe = (oos_excess_mean * 12) / (oos_excess_vol * np.sqrt(12)) if oos_excess_vol != 0 else float('nan')\n",
    "oos_mdd = max_drawdown(oos_total)\n",
    "oos_alpha_month, oos_beta_value, oos_resid_std = run_ols(oos_excess_series, part3_model_df['SPY_excess_next'].loc[oos_total.index])\n",
    "oos_alpha_ann = oos_alpha_month * 12\n",
    "oos_info = oos_alpha_ann / (oos_resid_std * np.sqrt(12)) if oos_resid_std != 0 else float('nan')\n",
    "oos_metrics = {\n",
    "    'Mean': mean_ann,\n",
    "    'Volatility': vol_ann,\n",
    "    'Sharpe': oos_sharpe,\n",
    "    'Max_Drawdown': oos_mdd,\n",
    "    'Alpha': oos_alpha_ann,\n",
    "    'Beta': oos_beta_value,\n",
    "    'Info_Ratio': oos_info\n",
    "}\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Version': 'In-sample DP_EP',\n",
    "        'Mean': strategy_metric_map['DP_EP']['Mean'],\n",
    "        'Volatility': strategy_metric_map['DP_EP']['Volatility'],\n",
    "        'Sharpe': strategy_metric_map['DP_EP']['Sharpe'],\n",
    "        'Max_Drawdown': strategy_metric_map['DP_EP']['Max_Drawdown'],\n",
    "        'Alpha': strategy_metric_map['DP_EP']['Alpha'],\n",
    "        'Beta': strategy_metric_map['DP_EP']['Beta'],\n",
    "        'Info_Ratio': strategy_metric_map['DP_EP']['Info_Ratio']\n",
    "    },\n",
    "    {\n",
    "        'Version': 'OOS DP_EP',\n",
    "        'Mean': oos_metrics['Mean'],\n",
    "        'Volatility': oos_metrics['Volatility'],\n",
    "        'Sharpe': oos_metrics['Sharpe'],\n",
    "        'Max_Drawdown': oos_metrics['Max_Drawdown'],\n",
    "        'Alpha': oos_metrics['Alpha'],\n",
    "        'Beta': oos_metrics['Beta'],\n",
    "        'Info_Ratio': oos_metrics['Info_Ratio']\n",
    "    }\n",
    "]).round(4)\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd73a440",
   "metadata": {},
   "source": [
    "The OOS strategy earns only about zero point zero seven annualized mean with a Sharpe near zero point twenty seven, compared with roughly zero point eleven mean and a Sharpe in the low zero point fifties for the in-sample DP plus EP variant. Alpha turns negative and the information ratio drops well below zero, highlighting how much performance relied on perfect hindsight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23972275",
   "metadata": {},
   "source": [
    "Q4.3\n",
    "**3. Redo 3.3 with OOS forecasts.** Is the point-in-time version of the strategy riskier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84878141",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_compare = pd.DataFrame([\n",
    "    {'Series': 'SPY', 'VaR_0.05': part3_model_df['return_next'].quantile(0.05)},\n",
    "    {'Series': 'GMWAX', 'VaR_0.05': part3_model_df['GMWAX_next'].quantile(0.05)},\n",
    "    {'Series': 'DP_EP strategy', 'VaR_0.05': strategy_totals['DP_EP'].quantile(0.05)},\n",
    "    {'Series': 'OOS DP_EP strategy', 'VaR_0.05': oos_total_series.quantile(0.05)}\n",
    "]).round(4)\n",
    "print(var_compare.to_string(index=False))\n",
    "\n",
    "oos_excess_window = (oos_total_series.loc[start_period:end_period] - part3_model_df['rf_next'].loc[start_period:end_period]).mean()\n",
    "print(f'OOS DP_EP mean excess two thousand to two thousand eleven: {oos_excess_window:0.4f}')\n",
    "\n",
    "oos_forecast_excess = (oos_forecast - part3_model_df['rf_next']).iloc[oos_start:]\n",
    "neg_oos = int(oos_forecast_excess.lt(0).sum())\n",
    "print(f'OOS DP_EP negative forecast count: {neg_oos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ae2c0",
   "metadata": {},
   "source": [
    "OOS VaR remains close to minus zero point zero six and the strategy still experiences a roughly minus zero point sixty eight drawdown, so the real-time version is at least as risky as the in-sample counterpart. The average excess return from two thousand to two thousand eleven is barely positive, and the model only produces a few dozen bearish forecasts once we limit ourselves to available data, underscoring that the live strategy would have taken substantial risk without materially better downside protection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
