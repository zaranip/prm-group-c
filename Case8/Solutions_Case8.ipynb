{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d12332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. READING\n",
    "# 1.\n",
    "# Securities traded -\n",
    "# Government bonds, swaps, equity derivatives and some volatility products.\n",
    "\n",
    "# Trading frequency\n",
    "# 6-months to 2-years (did not trade on a daily basis)\n",
    "\n",
    "# Skewness (Do they seek many small wins or a few big hits?)\n",
    "# They worked on small, steady, convergence trades which required a very large notional and were highly leveraged along with some rare, large loses.\n",
    "\n",
    "# Forecasting (What is behind their selection of trades?)\n",
    "# Convergence trades, certain mispricings, statistical arbitrage, mean reversion and the usage of some quantitative models (they would not take bets on the direction of the market)\n",
    "\n",
    "# 2\n",
    "# LTCM could borrow money from large institutions at very low haircuts due to the reputation of its founders. They also had access to complex mathemtical models and highly \n",
    "# skilled employees.\n",
    "# Repo financing was cheap.\n",
    "# They could lever their positions 20-30x higher than their competitors.\n",
    "\n",
    "# 3 \n",
    "# collateral haircuts -\n",
    "# (when LTCM borrowed money from lenders, they had to post some collateral (usually US Treasuries). The haircut is the % of that lenders impose on that collateral for \n",
    "# protection against market fluctuations)\n",
    "# a. LTCM managed risk by providing high-quality collateral such as US Treasuries. \n",
    "# b. Structured trades such that they hold the special, more liquid side of the trade that needed less collateral.\n",
    "# c. They diversified their counterparties to avoid concentration risk.\n",
    "# d. Maintains liquidity to absorb unexpected rise in haircuts.\n",
    "\n",
    "# repo maturity -\n",
    "# (LTCM borrowed money using repo agreements, wherein they would need to payback the lender once the repo matures)\n",
    "# a. LTCM managed this risk by making staggering repo agreements, i.e. having varied maturities, 1 week, 1 month, 3 months etc.\n",
    "# b. They had varied lenders, so incase one does not agree to roll-over they are not over-dependent.\n",
    "# c. They negiotiated longer terms.\n",
    "# d. They kept extra liquidity at hand. \n",
    "\n",
    "# equity redemption\n",
    "# (equity redemption is when investors want to withdraw their investments from the fund)\n",
    "# a. LTCM managed this risk by providing lockup periods. Investors cannot withdraw before 3 years from investment.\n",
    "# b. Withdrawal windows -  they provided certain windows when investors could withdraw their money and the Fund can manage their risk.\n",
    "# c. Long notice periods for redemptions.\n",
    "# d. Staged redemption windows to avoid conincident redemption from clients.\n",
    "\n",
    "# loan access\n",
    "# (LTCM needed some large sums of money to build their trades)\n",
    "# a. They managed loan risk by doing business with a large, varied set of banks.\n",
    "# b. Banks earned large fees from LTCM, so they maintained good relationships with each of them.\n",
    "# c. They posted good quality collateral such as US Treasuries to secure their loans.\n",
    "# d. They had great reputation and were transparent to some extent in their operations.\n",
    "\n",
    "# 4\n",
    "# Liquidity risk -\n",
    "# LTCM soon realised that the nature of their trades to make profits were usually a way to provide liquidity to the market.\n",
    "# a. They handled this by running backtests during previous market crashes and tracked the behaviour of spreads during those times and incorporated that into their models.\n",
    "# b. They ran VaR and stress-test scenarios in these market crash scenarios to check how liquidity requirements change. \n",
    "# c. Most importantly, during market crashes, correlation between assets increase (close to 1) and diversification benefits disappear. They used this fat tail distribution \n",
    "# in their models to see how the spreads would blow out and maintain that liquidity in their fund.\n",
    "\n",
    "# 5\n",
    "# Is leverage risk currently a concern for LTCM?\n",
    "# During 1994-1998, LTCM did not think that leverage was a major risk as they believed their trades were safe, backed by historical data, market neutral and hedged positions\n",
    "# and convergence based.\n",
    "# However, I believe for outsiders, leverage risk is very important as highly leverged positions can lead to large margin calls and bankrupty situations such as seen in LTCM's case\n",
    "\n",
    "# 6\n",
    "# risk in these convergence trades\n",
    "# The risk with convergence of trades is that when the spreads widen (even though eventually they would converge), the MTM losses would increase, triggering margin calls \n",
    "# and cause an increase in the liquidity requirements of the fund. This could potentially force the fund to liquidate their positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29b03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gross Excess Return Stats:\n",
      "Annualized Mean:           0.0029\n",
      "Annualized Volatility:     0.0014\n",
      "Sharpe Ratio:              2.1553\n",
      "Skewness:                  -0.2964\n",
      "Kurtosis (Pearson):        4.3141\n",
      "5th Percentile (monthly):  -0.0003\n",
      "\n",
      "Net Excess Return Stats:\n",
      "Annualized Mean:           0.0021\n",
      "Annualized Volatility:     0.0011\n",
      "Sharpe Ratio:              1.8513\n",
      "Skewness:                  -0.8179\n",
      "Kurtosis (Pearson):        5.5275\n",
      "5th Percentile (monthly):  -0.0002\n"
     ]
    }
   ],
   "source": [
    "# 1. Summary stats.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "FILE = \"ltcm_exhibits_data.xlsx\"\n",
    "SHEET = \"Exhibit 2\"\n",
    "\n",
    "df = pd.read_excel(FILE, sheet_name=SHEET, header=2, dtype=str)\n",
    "\n",
    "def pct_to_dec(s):\n",
    "    s = s.astype(str).str.strip()\n",
    "    s = s.str.replace(\",\", \"\", regex=True)\n",
    "    s = s.str.replace(\"%\", \"\", regex=True)\n",
    "    return pd.to_numeric(s, errors=\"coerce\") / 100.0\n",
    "\n",
    "gross = pct_to_dec(df[\"Gross Monthly Performancea\"])\n",
    "net   = pct_to_dec(df[\"Net Monthly Performanceb\"])\n",
    "\n",
    "gross = gross.dropna().reset_index(drop=True)\n",
    "net   = net.dropna().reset_index(drop=True)\n",
    "\n",
    "def summary_stats(series, freq=12):\n",
    "    ann_mean = series.mean() * freq\n",
    "    ann_vol  = series.std(ddof=1) * np.sqrt(freq)\n",
    "    sharpe   = ann_mean / ann_vol if ann_vol != 0 else np.nan\n",
    "    skewness = skew(series.dropna(), bias=False)\n",
    "    kurt     = kurtosis(series.dropna(), fisher=False)  \n",
    "    q5       = np.percentile(series.dropna(), 5)\n",
    "    return {\n",
    "        \"Annualized Mean\": ann_mean,\n",
    "        \"Annualized Volatility\": ann_vol,\n",
    "        \"Sharpe Ratio\": sharpe,\n",
    "        \"Skewness\": skewness,\n",
    "        \"Kurtosis (Pearson)\": kurt,\n",
    "        \"5th Percentile (monthly)\": q5\n",
    "    }\n",
    "\n",
    "def print_stats(name, stats):\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"Annualized Mean:           {stats['Annualized Mean']:.4f}\")\n",
    "    print(f\"Annualized Volatility:     {stats['Annualized Volatility']:.4f}\")\n",
    "    print(f\"Sharpe Ratio:              {stats['Sharpe Ratio']:.4f}\")\n",
    "    print(f\"Skewness:                  {stats['Skewness']:.4f}\")\n",
    "    print(f\"Kurtosis (Pearson):        {stats['Kurtosis (Pearson)']:.4f}\")\n",
    "    print(f\"5th Percentile (monthly):  {stats['5th Percentile (monthly)']:.4f}\")\n",
    "\n",
    "print_stats(\"Gross Excess Return Stats:\", summary_stats(gross))\n",
    "print_stats(\"Net Excess Return Stats:\", summary_stats(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c0fe7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LTCM Gross\n",
      "Mean (ann):      0.0029\n",
      "Vol (ann):       0.0014\n",
      "Sharpe:          2.1553\n",
      "Skewness:        -0.2964\n",
      "Kurtosis:        4.3141\n",
      "5th pct (month): -0.0003\n",
      "\n",
      "LTCM Net\n",
      "Mean (ann):      0.0021\n",
      "Vol (ann):       0.0011\n",
      "Sharpe:          1.8513\n",
      "Skewness:        -0.8179\n",
      "Kurtosis:        5.5275\n",
      "5th pct (month): -0.0002\n",
      "\n",
      "SPY Excess Return\n",
      "Mean (ann):      0.0716\n",
      "Vol (ann):       0.1499\n",
      "Sharpe:          0.4775\n",
      "Skewness:        -0.5597\n",
      "Kurtosis:        3.8662\n",
      "5th pct (month): -0.0741\n"
     ]
    }
   ],
   "source": [
    "# 2. Compare to SPY\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "SPY_FILE = \"spy_data.xlsx\"\n",
    "def pct_to_dec(s):\n",
    "    s = s.astype(str).str.strip()\n",
    "    s = s.str.replace(\",\", \"\", regex=True)\n",
    "    s = s.str.replace(\"%\", \"\", regex=True)\n",
    "    return pd.to_numeric(s, errors=\"coerce\") / 100.0\n",
    "\n",
    "def summary_stats(series, freq=12):\n",
    "    s = series.dropna().astype(float)\n",
    "    ann_mean = s.mean() * freq\n",
    "    ann_vol  = s.std(ddof=1) * np.sqrt(freq)\n",
    "    sharpe   = ann_mean / ann_vol if ann_vol != 0 else np.nan\n",
    "    skewness = skew(s, bias=False)\n",
    "    kurt_p   = kurtosis(s, fisher=False)    # Pearson\n",
    "    q5       = np.percentile(s, 5)\n",
    "    return {\n",
    "        \"Annualized Mean\": ann_mean,\n",
    "        \"Annualized Volatility\": ann_vol,\n",
    "        \"Sharpe Ratio\": sharpe,\n",
    "        \"Skewness\": skewness,\n",
    "        \"Kurtosis (Pearson)\": kurt_p,\n",
    "        \"5th Percentile (monthly)\": q5\n",
    "    }\n",
    "spy_df = pd.read_excel(SPY_FILE, sheet_name=\"excess returns\", dtype=str)\n",
    "spy = pd.to_numeric(spy_df[\"SPY\"], errors=\"coerce\").dropna().reset_index(drop=True)\n",
    "\n",
    "g_stats = summary_stats(gross)\n",
    "n_stats = summary_stats(net)\n",
    "spy_stats = summary_stats(spy)\n",
    "\n",
    "def pretty(label, stats):\n",
    "    print(f\"\\n{label}\")\n",
    "    print(f\"Mean (ann):      {stats['Annualized Mean']:.4f}\")\n",
    "    print(f\"Vol (ann):       {stats['Annualized Volatility']:.4f}\")\n",
    "    print(f\"Sharpe:          {stats['Sharpe Ratio']:.4f}\")\n",
    "    print(f\"Skewness:        {stats['Skewness']:.4f}\")\n",
    "    print(f\"Kurtosis:        {stats['Kurtosis (Pearson)']:.4f}\")\n",
    "    print(f\"5th pct (month): {stats['5th Percentile (monthly)']:.4f}\")\n",
    "\n",
    "# compute stats again quickly\n",
    "g_stats = summary_stats(gross)\n",
    "n_stats = summary_stats(net)\n",
    "s_stats = summary_stats(spy)\n",
    "\n",
    "pretty(\"LTCM Gross\", g_stats)\n",
    "pretty(\"LTCM Net\", n_stats)\n",
    "pretty(\"SPY Excess Return\", s_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ec3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much do they differ between gross and net?\n",
    "# Mean, vol and sharpe reduce rightly so as the fees are taken out from the gross returns.\n",
    "# Skewness is amplified as reduction in fees for +ve months is more noticeable than for -ve months.\n",
    "# Kurtosis increases slightly which means the difference between normal and outliers is amplifies, centre becomes thinner and tails fatter \n",
    "# 5th pct :- Fees reduce for positive normal months but not so much for negative months. Hence, 5th pct has not reduced much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9af0e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs: 53\n",
      "Monthly alpha: 0.00019437195827813757\n",
      "Annualized alpha: 0.002332463499337651\n",
      "Beta: -0.0017279020963310557\n",
      "R-squared: 0.03155360343667768\n",
      "                               OLS Regression Results                               \n",
      "====================================================================================\n",
      "Dep. Variable:     Net Monthly Performanceb   R-squared:                       0.032\n",
      "Model:                                  OLS   Adj. R-squared:                  0.013\n",
      "Method:                       Least Squares   F-statistic:                     1.662\n",
      "Date:                      Tue, 25 Nov 2025   Prob (F-statistic):              0.203\n",
      "Time:                              19:25:07   Log-Likelihood:                 352.15\n",
      "No. Observations:                        53   AIC:                            -700.3\n",
      "Df Residuals:                            51   BIC:                            -696.4\n",
      "Df Model:                                 1                                         \n",
      "Covariance Type:                  nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0002   4.72e-05      4.118      0.000    9.96e-05       0.000\n",
      "SPY           -0.0017      0.001     -1.289      0.203      -0.004       0.001\n",
      "==============================================================================\n",
      "Omnibus:                       14.114   Durbin-Watson:                   1.784\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               22.363\n",
      "Skew:                          -0.822   Prob(JB):                     1.39e-05\n",
      "Kurtosis:                       5.725   Cond. No.                         30.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# 3. LFD\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def pct_to_dec(s):\n",
    "    s = s.astype(str).str.strip().str.replace(\",\", \"\", regex=True).str.replace(\"%\",\"\",regex=True)\n",
    "    return pd.to_numeric(s, errors=\"coerce\")/100.0\n",
    "\n",
    "# Align lengths\n",
    "n = min(len(net), len(spy))\n",
    "net = net.iloc[:n].reset_index(drop=True)\n",
    "spy = spy.iloc[:n].reset_index(drop=True)\n",
    "\n",
    "# Regression\n",
    "X = sm.add_constant(spy)\n",
    "model = sm.OLS(net, X).fit()\n",
    "\n",
    "alpha_month = model.params['const']\n",
    "beta = model.params['SPY']\n",
    "r2 = model.rsquared\n",
    "alpha_annual = alpha_month * 12\n",
    "\n",
    "print(\"Obs:\", n)\n",
    "print(\"Monthly alpha:\", alpha_month)\n",
    "print(\"Annualized alpha:\", alpha_annual)\n",
    "print(\"Beta:\", beta)\n",
    "print(\"R-squared:\", r2)\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeb7775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does LTCM deliver performance beyond SPY?\n",
    "# I dont think LTCM delivers performance any better than SPY. Infact it has a -ve beta and a very minmal alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7aa38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonlinear Factor Regression: Net LTCM excess ~ SPY + SPY^2\n",
      "\n",
      "Annualized alpha: 0.001836\n",
      "Linear beta:      -0.002197\n",
      "Quadratic beta:   0.038140\n",
      "R-squared:        0.053735\n",
      "\n",
      "Regression summary:\n",
      "                               OLS Regression Results                               \n",
      "====================================================================================\n",
      "Dep. Variable:     Net Monthly Performanceb   R-squared:                       0.054\n",
      "Model:                                  OLS   Adj. R-squared:                  0.016\n",
      "Method:                       Least Squares   F-statistic:                     1.420\n",
      "Date:                      Tue, 25 Nov 2025   Prob (F-statistic):              0.251\n",
      "Time:                              19:28:22   Log-Likelihood:                 352.76\n",
      "No. Observations:                        53   AIC:                            -699.5\n",
      "Df Residuals:                            50   BIC:                            -693.6\n",
      "Df Model:                                 2                                         \n",
      "Covariance Type:                  nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0002   6.07e-05      2.520      0.015    3.11e-05       0.000\n",
      "SPY           -0.0022      0.001     -1.562      0.125      -0.005       0.001\n",
      "SPY_sq         0.0381      0.035      1.083      0.284      -0.033       0.109\n",
      "==============================================================================\n",
      "Omnibus:                       12.245   Durbin-Watson:                   1.582\n",
      "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               19.663\n",
      "Skew:                          -0.683   Prob(JB):                     5.37e-05\n",
      "Kurtosis:                       5.653   Cond. No.                         800.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# 4. Nonlinear Exposure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "n = min(len(net), len(spy))\n",
    "y = net.iloc[:n].reset_index(drop=True)\n",
    "x1 = spy.iloc[:n].reset_index(drop=True)\n",
    "x2 = x1 ** 2   # quadratic term\n",
    "\n",
    "# Build regression matrix\n",
    "X = pd.DataFrame({\n",
    "    \"const\": 1,\n",
    "    \"SPY\": x1,\n",
    "    \"SPY_sq\": x2\n",
    "})\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "alpha_month = model.params[\"const\"]\n",
    "alpha_annual = alpha_month * 12\n",
    "beta_linear = model.params[\"SPY\"]\n",
    "beta_quadratic = model.params[\"SPY_sq\"]\n",
    "r2 = model.rsquared\n",
    "\n",
    "print(\"Nonlinear Factor Regression: Net LTCM excess ~ SPY + SPY^2\\n\")\n",
    "print(f\"Annualized alpha: {alpha_annual:.6f}\")\n",
    "print(f\"Linear beta:      {beta_linear:.6f}\")\n",
    "print(f\"Quadratic beta:   {beta_quadratic:.6f}\")\n",
    "print(f\"R-squared:        {r2:.6f}\")\n",
    "\n",
    "print(\"\\nRegression summary:\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd979325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the quadratic market factor do much to increase the overall LTCM variation explained by the market?\n",
    "# No, the quadratic market factor R^2 does not do much to increase the variation. It is a very small increase from 0.031 of the lFD.\n",
    "# This means that SPY is not the right factor to explain LTCM's returns. Perhaps a fixed income factor could explain it better.\n",
    "\n",
    "# From the regression evidence, does LTCM’s market exposure behave as if it is long market options or short market options?\n",
    "# LTCM's exposure behaves as if it is slightly long market options since it has a +ve beta 2. However, as mentioned above we are using SPY -\n",
    "# equity markets as a factor to explain it which is not right, a fixed income volatility factor would be better.\n",
    "\n",
    "# Should we describe LTCM as being positively or negatively exposed to market volatility?\n",
    "# This would be slightly tough to say as again, its marginally positively exposed to equity market volatility.\n",
    "# But we have seen in the case that it has -ve exposure to fixed income volatility and liquidity shocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ba0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annualized alpha: 0.0020344644953157647\n",
      "Market beta: -0.0021773073570376896\n",
      "Up beta (beta_u): 0.0041619386931250665\n",
      "Down beta (beta_d): 0.0038850092266366487\n",
      "R-squared: 0.0517004567321776\n",
      "\n",
      "Regression summary:\n",
      "                               OLS Regression Results                               \n",
      "====================================================================================\n",
      "Dep. Variable:     Net Monthly Performanceb   R-squared:                       0.052\n",
      "Model:                                  OLS   Adj. R-squared:                 -0.006\n",
      "Method:                       Least Squares   F-statistic:                    0.8905\n",
      "Date:                      Tue, 25 Nov 2025   Prob (F-statistic):              0.453\n",
      "Time:                              22:28:53   Log-Likelihood:                 352.71\n",
      "No. Observations:                        53   AIC:                            -697.4\n",
      "Df Residuals:                            49   BIC:                            -689.5\n",
      "Df Model:                                 3                                         \n",
      "Covariance Type:                  nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0002   6.04e-05      2.808      0.007    4.82e-05       0.000\n",
      "market        -0.0022      0.003     -0.784      0.437      -0.008       0.003\n",
      "up             0.0042      0.006      0.664      0.510      -0.008       0.017\n",
      "down           0.0039      0.011      0.342      0.734      -0.019       0.027\n",
      "==============================================================================\n",
      "Omnibus:                       13.117   Durbin-Watson:                   1.598\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.481\n",
      "Skew:                          -0.734   Prob(JB):                     2.16e-05\n",
      "Kurtosis:                       5.752   Cond. No.                         272.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# 6.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def pct_to_dec(s):\n",
    "    s = s.astype(str).str.strip().str.replace(\",\", \"\", regex=True).str.replace(\"%\",\"\",regex=True)\n",
    "    return pd.to_numeric(s, errors=\"coerce\")/100.0\n",
    "\n",
    "net = pct_to_dec(lt[\"Net Monthly Performanceb\"]).dropna().reset_index(drop=True)\n",
    "spy = pd.to_numeric(spy_df[\"SPY\"], errors=\"coerce\").dropna().reset_index(drop=True)\n",
    "\n",
    "# Align lengths\n",
    "n = min(len(net), len(spy))\n",
    "net = net[:n]\n",
    "spy = spy[:n]\n",
    "\n",
    "k1 = 0.03     # +3%\n",
    "k2 = -0.03    # -3%\n",
    "\n",
    "market = spy\n",
    "up = np.maximum(spy - k1, 0)      # only kicks in above +3%\n",
    "down = np.maximum(k2 - spy, 0)    # only kicks in below -3%\n",
    "\n",
    "X = pd.DataFrame({\n",
    "    \"const\": 1.0,\n",
    "    \"market\": market,\n",
    "    \"up\": up,\n",
    "    \"down\": down\n",
    "})\n",
    "\n",
    "model = sm.OLS(net, X).fit()\n",
    "\n",
    "alpha_month = model.params[\"const\"]\n",
    "alpha_annual = alpha_month * 12\n",
    "beta_market = model.params[\"market\"]\n",
    "beta_up = model.params[\"up\"]\n",
    "beta_down = model.params[\"down\"]\n",
    "r2 = model.rsquared\n",
    "\n",
    "print(\"Annualized alpha:\", alpha_annual)\n",
    "print(\"Market beta:\", beta_market)\n",
    "print(\"Up beta (beta_u):\", beta_up)\n",
    "print(\"Down beta (beta_d):\", beta_down)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "print(\"\\nRegression summary:\")\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50487477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7\n",
    "# Is LTCM long or short the call-like factor? And the put-like factor?\n",
    "# LTCM is only slightly like the call and put factor both since beta up and beta down are 0.4% and 0.38% respectively and both are \n",
    "# too small compared to 3% thresholds. So, tough to say definitively.T\n",
    "\n",
    "# Which factor moves LTCM more, the call-like factor, or the put-like factor?\n",
    "# The call factor moves LTCM slightly more but the difference is very very small.\n",
    "\n",
    "# In the previous problem, you commented on whether LTCM is positively or negatively exposed to market volatility. \n",
    "# Using this current regression, does this volatility exposure come more from being long the market’s upside? Short the market’s downside? Something else?\n",
    "# The volatility exposure comes from neither long the market's upside or short, since both the betas are significantly small. \n",
    "# This makes my previous statement that LTCM's exposure comes more from fixed income volatility, liquidity shocks, swap spread\n",
    "# blowouts etc and not from equity markets.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
